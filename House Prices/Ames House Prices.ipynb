{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a Spark session to start...\n",
      "Spark Initialization Done! ApplicationId = app-20200402091815-0000\n",
      "KERNEL_ID = 93816d4d-bfbc-4bfd-8260-2608561fc5ef\n"
     ]
    }
   ],
   "source": [
    "# @hidden_cell\n",
    "# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n",
    "from project_lib import Project\n",
    "project = Project(spark.sparkContext, '0062b6b9-363a-48ea-8273-51b639cd0891', 'p-577ee47309c0be1153ed7c39d05c265f9295d159')\n",
    "pc = project.project_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training data from IBM cloud\n",
    "\n",
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "\n",
    "}\n",
    "\n",
    "configuration_name = 'os_c63666ea1c9d403e811d4c86742ad623_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load(cos.url('train.csv', 'bostonhousing-donotdelete-pr-f7plktwicr9r0f'), inferSchema='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>169277.052498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  169277.052498"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the test set to be submitted to Kaggle as Spark dataframe. Use schema from the train set.\n",
    "df_test = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load(cos.url('test.csv', 'bostonhousing-donotdelete-pr-f7plktwicr9r0f'), inferSchema= 'true')#schema=df_data_train.schema)\n",
    "#df_test.take(1)\n",
    "\n",
    "\n",
    "#Import the sample submission for Kaggle as pandas dataframe\n",
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "\n",
    "body = client_c63666ea1c9d403e811d4c86742ad623.get_object(Bucket='bostonhousing-donotdelete-pr-f7plktwicr9r0f',Key='sample_submission.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "sample_sub = pd.read_csv(body)\n",
    "sample_sub.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are missing values (there are none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0   0           0        0            0            0          0             0   \n",
       "\n",
       "   BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  WoodDeckSF  OpenPorchSF  \\\n",
       "0           0           0          0  ...           0            0   \n",
       "\n",
       "   EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "0              0          0            0         0        0       0       0   \n",
       "\n",
       "   SalePrice  \n",
       "0          0  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "def count_missings(spark_df,sort=True):\n",
    "    df = spark_df.select([F.count(F.when(F.isnan(c) | F.isnull(c), c)).alias(c) for (c,c_type) in spark_df.dtypes if c_type not in ('timestamp', 'string', 'date')]).toPandas()\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"There are no any missing values!\")\n",
    "        return None\n",
    "\n",
    "    if sort:\n",
    "        return df.rename(index={0: 'count'}).T.sort_values(\"count\",ascending=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "count_missings(df_test, False)\n",
    "count_missings(df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'LotFrontage', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
      "['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice']\n"
     ]
    }
   ],
   "source": [
    "# Create two separate lists of categorical and numerical features\n",
    "columns_cat = [item[0] for item in df.dtypes if item[1].startswith('string')]\n",
    "columns_num = [item[0] for item in df.dtypes if item[1].startswith('int') | item[1].startswith('double')]\n",
    "\n",
    "print(columns_cat)\n",
    "print(columns_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"NA\" in test set with 0\n",
    "df_test = df_test.replace('NA', '0')\n",
    "for col in columns_num:\n",
    "    if (col == 'SalePrice') | (col == 'Id'):\n",
    "        continue\n",
    "    df_test = df_test.withColumn(col, df_test[col].cast('double'))\n",
    "    df = df.withColumn(col, df[col].cast('double'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the schema of the dataframe looks ok (features that are categorical should be strings, numeric features should be integers or double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- MSSubClass: double (nullable = true)\n",
      " |-- MSZoning: string (nullable = true)\n",
      " |-- LotFrontage: string (nullable = true)\n",
      " |-- LotArea: double (nullable = true)\n",
      " |-- Street: string (nullable = true)\n",
      " |-- Alley: string (nullable = true)\n",
      " |-- LotShape: string (nullable = true)\n",
      " |-- LandContour: string (nullable = true)\n",
      " |-- Utilities: string (nullable = true)\n",
      " |-- LotConfig: string (nullable = true)\n",
      " |-- LandSlope: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Condition1: string (nullable = true)\n",
      " |-- Condition2: string (nullable = true)\n",
      " |-- BldgType: string (nullable = true)\n",
      " |-- HouseStyle: string (nullable = true)\n",
      " |-- OverallQual: double (nullable = true)\n",
      " |-- OverallCond: double (nullable = true)\n",
      " |-- YearBuilt: double (nullable = true)\n",
      " |-- YearRemodAdd: double (nullable = true)\n",
      " |-- RoofStyle: string (nullable = true)\n",
      " |-- RoofMatl: string (nullable = true)\n",
      " |-- Exterior1st: string (nullable = true)\n",
      " |-- Exterior2nd: string (nullable = true)\n",
      " |-- MasVnrType: string (nullable = true)\n",
      " |-- MasVnrArea: string (nullable = true)\n",
      " |-- ExterQual: string (nullable = true)\n",
      " |-- ExterCond: string (nullable = true)\n",
      " |-- Foundation: string (nullable = true)\n",
      " |-- BsmtQual: string (nullable = true)\n",
      " |-- BsmtCond: string (nullable = true)\n",
      " |-- BsmtExposure: string (nullable = true)\n",
      " |-- BsmtFinType1: string (nullable = true)\n",
      " |-- BsmtFinSF1: double (nullable = true)\n",
      " |-- BsmtFinType2: string (nullable = true)\n",
      " |-- BsmtFinSF2: double (nullable = true)\n",
      " |-- BsmtUnfSF: double (nullable = true)\n",
      " |-- TotalBsmtSF: double (nullable = true)\n",
      " |-- Heating: string (nullable = true)\n",
      " |-- HeatingQC: string (nullable = true)\n",
      " |-- CentralAir: string (nullable = true)\n",
      " |-- Electrical: string (nullable = true)\n",
      " |-- 1stFlrSF: double (nullable = true)\n",
      " |-- 2ndFlrSF: double (nullable = true)\n",
      " |-- LowQualFinSF: double (nullable = true)\n",
      " |-- GrLivArea: double (nullable = true)\n",
      " |-- BsmtFullBath: double (nullable = true)\n",
      " |-- BsmtHalfBath: double (nullable = true)\n",
      " |-- FullBath: double (nullable = true)\n",
      " |-- HalfBath: double (nullable = true)\n",
      " |-- BedroomAbvGr: double (nullable = true)\n",
      " |-- KitchenAbvGr: double (nullable = true)\n",
      " |-- KitchenQual: string (nullable = true)\n",
      " |-- TotRmsAbvGrd: double (nullable = true)\n",
      " |-- Functional: string (nullable = true)\n",
      " |-- Fireplaces: double (nullable = true)\n",
      " |-- FireplaceQu: string (nullable = true)\n",
      " |-- GarageType: string (nullable = true)\n",
      " |-- GarageYrBlt: string (nullable = true)\n",
      " |-- GarageFinish: string (nullable = true)\n",
      " |-- GarageCars: double (nullable = true)\n",
      " |-- GarageArea: double (nullable = true)\n",
      " |-- GarageQual: string (nullable = true)\n",
      " |-- GarageCond: string (nullable = true)\n",
      " |-- PavedDrive: string (nullable = true)\n",
      " |-- WoodDeckSF: double (nullable = true)\n",
      " |-- OpenPorchSF: double (nullable = true)\n",
      " |-- EnclosedPorch: double (nullable = true)\n",
      " |-- 3SsnPorch: double (nullable = true)\n",
      " |-- ScreenPorch: double (nullable = true)\n",
      " |-- PoolArea: double (nullable = true)\n",
      " |-- PoolQC: string (nullable = true)\n",
      " |-- Fence: string (nullable = true)\n",
      " |-- MiscFeature: string (nullable = true)\n",
      " |-- MiscVal: double (nullable = true)\n",
      " |-- MoSold: double (nullable = true)\n",
      " |-- YrSold: double (nullable = true)\n",
      " |-- SaleType: string (nullable = true)\n",
      " |-- SaleCondition: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the PoolArea feature with a Has Pool feature, there are very few houses with pools in the dataset (only 7 of 1460)\n",
    "#from pyspark.ml.feature import Binarizer\n",
    "\n",
    "#df = df.withColumn(\"PoolArea\", df.PoolArea.cast(\"double\"))\n",
    "\n",
    "#binarizer = Binarizer(threshold=0.0, inputCol='PoolArea', outputCol='Has_Pool')\n",
    "\n",
    "#df = binarizer.transform(df)\n",
    "\n",
    "#df = df.drop('PoolArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BsmtFinSF1', 'Fireplaces', 'YearRemodAdd', 'YearBuilt', 'TotRmsAbvGrd', 'FullBath', '1stFlrSF', 'TotalBsmtSF', 'GarageArea', 'GarageCars', 'GrLivArea', 'OverallQual']\n"
     ]
    }
   ],
   "source": [
    "# Find correlation between numerical features and the sale price\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "corr_list = []\n",
    "\n",
    "for column in columns_num:\n",
    "    corr_val = df.corr('SalePrice', column)\n",
    "    corr_list.append((column, corr_val))\n",
    "\n",
    "corr_list = sorted(corr_list, key=itemgetter(1))\n",
    "\n",
    "\n",
    "num_cols = []\n",
    "\n",
    "# Create list of numerical cols with a correlation above 0.35 with the sale price\n",
    "for col, val in corr_list:\n",
    "    if col == 'SalePrice':\n",
    "        continue\n",
    "    if val > 0.35:\n",
    "        num_cols.append(col)\n",
    "\n",
    "print(num_cols)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BsmtFinSF1', 'Fireplaces', 'YearRemodAdd', 'YearBuilt', 'TotRmsAbvGrd', 'FullBath', '1stFlrSF', 'TotalBsmtSF', 'GarageArea', 'GarageCars', 'GrLivArea', 'OverallQual', 'MSZoning', 'Neighborhood', 'HouseStyle', 'CentralAir', 'SalePrice']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "cat_cols = ['MSZoning', 'Neighborhood' , 'HouseStyle', 'CentralAir']\n",
    "\n",
    "cols_for_model = num_cols + cat_cols + ['SalePrice']\n",
    "\n",
    "df_red = df[cols_for_model]\n",
    "\n",
    "stages = []\n",
    "\n",
    "# Convert categorical strings to index values\n",
    "for cat_col in cat_cols:\n",
    "    indexer = StringIndexer(inputCol=cat_col, outputCol= cat_col +'_idx')\n",
    "    onehot = OneHotEncoderEstimator(inputCols=[indexer.getOutputCol()], outputCols= [cat_col + '_dummy'])\n",
    "    stages += [indexer, onehot]\n",
    "\n",
    "\n",
    "\n",
    "# Assemble predictors into a single column \n",
    "assembler = VectorAssembler(inputCols=num_cols, outputCol='features')\n",
    "\n",
    "stages += [assembler]\n",
    "\n",
    "h_train, h_test = df_red.randomSplit([0.8, 0.2], seed=1)\n",
    "\n",
    "# Print out columns to be used in prediction\n",
    "print(h_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradient boosted tree regressor\n",
    "gbt = GBTRegressor(featuresCol='features',\n",
    "                           labelCol='SalePrice',\n",
    "                           seed=1,\n",
    "                           stepSize = 0.05,\n",
    "                           maxIter = 100\n",
    "                           )\n",
    "\n",
    "\n",
    "stages += [gbt]\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Create the evaluator, evaluate on Root mean square error\n",
    "pip_evaluator = RegressionEvaluator(\n",
    "    labelCol='SalePrice', predictionCol='prediction', metricName='rmse')\n",
    "\n",
    "# Create a parameter grid to try different parameters\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, [4, 5])\n",
    "             .build())\n",
    "\n",
    "\n",
    "# Use cross validation to find the best model\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=pip_evaluator, numFolds=5, seed=1)\n",
    "\n",
    "cvModel = cv.fit(h_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StringIndexer_adcc7d7e8e8a, OneHotEncoderEstimator_9797e49b61e3, StringIndexer_0784cb5836fb, OneHotEncoderEstimator_66d04ff38864, StringIndexer_2b9b37d1a9a6, OneHotEncoderEstimator_08855e3f82dc, StringIndexer_900c06aaea2c, OneHotEncoderEstimator_2c9724a2be1d, VectorAssembler_4aca3cec6fef, GBTRegressionModel (uid=GBTRegressor_b10fb6198a6b) with 100 trees]\n",
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5, current: 4)\n",
      "Root Mean Squared Error (RMSE) on test data = 29068.5\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from cross validation\n",
    "best_model = cvModel.bestModel\n",
    "\n",
    "# Look at the stages in the best model\n",
    "print(best_model.stages)\n",
    "\n",
    "# select stage 9 (the GBTRegressor) of the best model and see info regarding which depth the model has chosen, this can be used on any parameter\n",
    "print(best_model.stages[9].explainParam('maxDepth'))\n",
    "\n",
    "# Generate predictions on testing data using the best model then calculate RMSE\n",
    "predictions = best_model.transform(h_test)\n",
    "rmse = pip_evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the prices for the test set and create a submission file for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id      SalePrice\n",
      "0  1461  118917.510767\n",
      "1  1462  148098.012267\n",
      "2  1463  194026.610188\n",
      "3  1464  192868.505328\n",
      "4  1465  193203.012501\n"
     ]
    }
   ],
   "source": [
    "# Choose the columns\n",
    "df_test_red = df_test[num_cols + cat_cols]\n",
    "df_test = df_test.fillna(0, subset=columns_num)\n",
    "\n",
    "# Make prediction\n",
    "kaggle_pred = best_model.transform(df_test)\n",
    "\n",
    "kaggle_pred = kaggle_pred.withColumn('Id', kaggle_pred['Id'].cast('int'))\n",
    "\n",
    "# Select only the required columns and convert to pandas dataframe for export\n",
    "kp_pandas = kaggle_pred.select('prediction', 'Id').toPandas()\n",
    "\n",
    "kp_pandas['SalePrice'] = kp_pandas.prediction\n",
    "kp_pandas = kp_pandas.drop(columns=['prediction'])\n",
    "print(kp_pandas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data to a csv-file to be able to submit the results to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'submission8.csv',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'bostonhousing-donotdelete-pr-f7plktwicr9r0f',\n",
       " 'asset_id': 'd8ff00d2-bb17-4f24-b46b-c0adaa1ea019'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save_data(\"submission8.csv\", kp_pandas.to_csv(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
