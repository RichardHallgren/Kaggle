{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from geopy import distance\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_data_light():\n",
    "    col_datatypes = {'fare_amount': 'float32',\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8'}\n",
    "    \n",
    "    cols = list(col_datatypes.keys())\n",
    "    \n",
    "    n = 10\n",
    "    X_light = pd.read_csv('train.csv', dtype=col_datatypes, header=0, usecols=cols,\n",
    "                         skiprows= lambda i : i % n != 0)\n",
    "    X_light['pickup_datetime'] = X_light['pickup_datetime'].str.slice(0, 16)\n",
    "    X_light['pickup_datetime'] = pd.to_datetime(X_light['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "    \n",
    "    print(X_light.info())\n",
    "    \n",
    "    \n",
    "    return X_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_data_testset():\n",
    "    col_datatypes = {\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8',\n",
    "                'key' : 'str'}\n",
    "    cols = list(col_datatypes.keys())\n",
    "    \n",
    "    X_test = pd.read_csv('test.csv', dtype=col_datatypes, header=0, usecols=cols)\n",
    "    \n",
    "\n",
    "    \n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_data_full():\n",
    "    col_datatypes = {'fare_amount': 'float32',\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8'}\n",
    "    \n",
    "    cols = list(col_datatypes.keys())\n",
    "    \n",
    "    X_full = pd.read_csv('train.csv', dtype=col_datatypes, header=0, usecols=cols)\n",
    "    \n",
    "    X_full['pickup_datetime'] = X_full['pickup_datetime'].str.slice(0, 16)\n",
    "    X_full['pickup_datetime'] = pd.to_datetime(X_full['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    #print(len(X_full[X_full['pickup_latitude'] > 45].index.tolist()))\n",
    "\n",
    "    \n",
    "    return X_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nyc_mapping():\n",
    "    #lat / lon vertices of Manhattan_polygon\n",
    "    v0 = [40.697509, -74.011890]\n",
    "    v1 = [40.701999, -74.023220]\n",
    "    v2 = [40.756686, -74.013898]\n",
    "    v3 = [40.828630, -73.962295]\n",
    "    v4 = [40.881317, -73.934646]\n",
    "    v5 = [40.872590, -73.909950]\n",
    "    v6 = [40.835231, -73.933841]\n",
    "    v7 = [40.809128, -73.933438]\n",
    "    v8 = [40.800289, -73.927667]\n",
    "    v9 = [40.774376, -73.939880]\n",
    "    v10 = [40.738207, -73.967730]\n",
    "    v11 = [40.708912, -73.974576]\n",
    "    v12 = [40.704944, -73.998735]\n",
    "    \n",
    "    vx = [v1,v2,v3,v4,v5,v6,v7,v8,v9,v10,v11,v12]\n",
    "    Manhattan_polygon = Polygon(vx)\n",
    "\n",
    "    #lat / lon vertices of JFK Airport\n",
    "    \n",
    "    jf1 = [40.622718, -73.770487]\n",
    "    jf2 = [40.648282, -73.829434]\n",
    "    jf3 = [40.666631, -73.833526]\n",
    "    jf4 = [40.669141, -73.801063]\n",
    "    jf5 = [40.668668, -73.781136]\n",
    "    jf6 = [40.640110, -73.736205]\n",
    "    \n",
    "    jfx = [jf1, jf2, jf3, jf4, jf5, jf6]\n",
    "    \n",
    "    JFK_polygon = Polygon(jfx)\n",
    "    \n",
    "    #lat / lon vertices of Newark airport\n",
    "    \n",
    "    n1 = [40.663831, -74.179334]\n",
    "    n2 = [40.680684, -74.195557]\n",
    "    n3 = [40.691124, -74.198349]\n",
    "    n4 = [40.712151, -74.181308]\n",
    "    n5 = [40.709275, -74.148121]\n",
    "    n6 = [40.687747, -74.159393]\n",
    "    \n",
    "    nx = [n1, n2, n3, n4, n5, n6]\n",
    "    \n",
    "    Newark_polygon = Polygon(nx)\n",
    "    \n",
    "\n",
    "    #testy = Point(40.831296, -73.923056) #test of location in Bronx\n",
    "    #testjfk = Point(40.646945, -73.789158) #test of location at JFK\n",
    "    \n",
    "    #print(Manhattan_polygon.contains(testy))\n",
    "    #print(JFK_polygon.contains(testjfk))\n",
    "    locations = [Manhattan_polygon, JFK_polygon, Newark_polygon]\n",
    "\n",
    "\n",
    "    \n",
    "    return locations    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_mapping(lat, lon):\n",
    "    Manhattan_polygon = nyc_mapping()[0]\n",
    "    JFK = nyc_mapping()[1]\n",
    "    Newark = nyc_mapping()[2]\n",
    "\n",
    "\n",
    "    location = 'unknown'\n",
    "    \n",
    "    if Manhattan_polygon.contains(Point(lat, lon)):\n",
    "        location = 'Manhattan'\n",
    "        \n",
    "    if location == 'unknown' and JFK.contains(Point(lat, lon)):\n",
    "        location = 'JFK'\n",
    "    \n",
    "    if location == 'unknown' and Newark.contains(Point(lat, lon)):\n",
    "        location = 'Newark'\n",
    "    \n",
    "    return location\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5542385 entries, 0 to 5542384\n",
      "Data columns (total 7 columns):\n",
      "fare_amount          float32\n",
      "pickup_datetime      datetime64[ns, UTC]\n",
      "pickup_longitude     float32\n",
      "pickup_latitude      float32\n",
      "dropoff_longitude    float32\n",
      "dropoff_latitude     float32\n",
      "passenger_count      uint8\n",
      "dtypes: datetime64[ns, UTC](1), float32(5), uint8(1)\n",
      "memory usage: 153.3 MB\n",
      "None\n",
      "         fare_amount           pickup_datetime  pickup_longitude  \\\n",
      "0                8.9 2009-09-02 01:11:00+00:00          -73.9807   \n",
      "1                4.0 2014-12-06 20:36:00+00:00          -73.9798   \n",
      "2                4.5 2013-08-11 00:52:00+00:00          -73.9810   \n",
      "3                9.8 2009-03-02 20:42:00+00:00          -73.9727   \n",
      "4                9.0 2013-01-29 12:26:00+00:00          -73.9923   \n",
      "...              ...                       ...               ...   \n",
      "5542380          4.9 2009-07-18 17:22:00+00:00          -73.9843   \n",
      "5542381          5.0 2013-11-02 02:24:00+00:00          -73.9557   \n",
      "5542382          5.5 2013-07-20 13:31:00+00:00          -73.9535   \n",
      "5542383          8.1 2012-03-15 07:33:00+00:00          -74.0042   \n",
      "5542384         12.0 2014-03-04 22:25:00+00:00          -73.9830   \n",
      "\n",
      "         pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
      "0                40.7339           -73.9915           40.7581   \n",
      "1                40.7519           -73.9794           40.7555   \n",
      "2                40.7378           -73.9807           40.7305   \n",
      "3                40.7592           -73.9699           40.7914   \n",
      "4                40.7427           -73.9836           40.7559   \n",
      "...                  ...                ...               ...   \n",
      "5542380          40.7289           -73.9831           40.7379   \n",
      "5542381          40.7683           -73.9478           40.7822   \n",
      "5542382          40.7787           -73.9632           40.7690   \n",
      "5542383          40.7383           -73.9797           40.7618   \n",
      "5542384          40.7451           -73.9542           40.7673   \n",
      "\n",
      "         passenger_count  cityblock_dist      dist Pickup_area Dropoff_area  \\\n",
      "0                      2          0.0350  2.837964   Manhattan    Manhattan   \n",
      "1                      1          0.0040  0.401201   Manhattan    Manhattan   \n",
      "2                      2          0.0076  0.811052   Manhattan    Manhattan   \n",
      "3                      1          0.0350  3.583600   Manhattan    Manhattan   \n",
      "4                      1          0.0219  1.639682   Manhattan    Manhattan   \n",
      "...                  ...             ...       ...         ...          ...   \n",
      "5542380                1          0.0102  1.004566   Manhattan    Manhattan   \n",
      "5542381                1          0.0218  1.681502   Manhattan    Manhattan   \n",
      "5542382                1          0.0194  1.353110   Manhattan    Manhattan   \n",
      "5542383                1          0.0480  3.330372   Manhattan    Manhattan   \n",
      "5542384                1          0.0510  3.462988   Manhattan    Manhattan   \n",
      "\n",
      "         weekday  hour  year  \n",
      "0              2     1  2009  \n",
      "1              5    20  2014  \n",
      "2              6     0  2013  \n",
      "3              0    20  2009  \n",
      "4              1    12  2013  \n",
      "...          ...   ...   ...  \n",
      "5542380        5    17  2009  \n",
      "5542381        5     2  2013  \n",
      "5542382        5    13  2013  \n",
      "5542383        3     7  2012  \n",
      "5542384        1    22  2014  \n",
      "\n",
      "[5427231 rows x 14 columns]\n",
      "Missing value columns: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:17:39] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
     ]
    }
   ],
   "source": [
    "def taxi_fare():\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from xgboost import XGBRegressor\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    import matplotlib.pyplot as plt\n",
    "    import scipy as sp\n",
    "    %matplotlib notebook\n",
    "\n",
    "    X_test_full = taxi_data_testset()\n",
    "    \n",
    "    X_test_full_unmod = X_test_full.copy()\n",
    "    \n",
    "    X_test_full['pickup_datetime'] = X_test_full['pickup_datetime'].str.slice(0, 16)\n",
    "    X_test_full['pickup_datetime'] = pd.to_datetime(X_test_full['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "    X_test_full['dist'] = X_test_full.apply(lambda x: distance.distance((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)).km, axis=1)\n",
    "    X_test_full['Pickup_area'] = X_test_full.apply(lambda x: loc_mapping(x.pickup_latitude, x.pickup_longitude), axis=1)\n",
    "    X_test_full['Dropoff_area'] = X_test_full.apply(lambda x: loc_mapping(x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "    X_test_full['weekday'] = X_test_full['pickup_datetime'].dt.dayofweek\n",
    "    X_test_full['hour'] = X_test_full['pickup_datetime'].dt.hour\n",
    "    X_test_full['year'] = X_test_full['pickup_datetime'].dt.year\n",
    "    X_test_full.drop(['pickup_datetime'], axis=1,inplace=True)\n",
    "    X_test_full.drop(['key'], axis=1,inplace=True)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #X = taxi_data_full() \n",
    "    X = taxi_data_light()\n",
    "    cols = ['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "\n",
    "    for col in cols:\n",
    "        X[col] = X[col].astype(float).round(4)\n",
    "        \n",
    "    #drop rows with deviating values and NaN\n",
    "    X.drop(X[(X['pickup_latitude'] > 45) | (X['dropoff_latitude'] > 45) \n",
    "                      | (X['pickup_latitude'] < 35) | (X['dropoff_latitude'] < 35)].index.tolist(), inplace=True)\n",
    "    \n",
    "    X.drop(X[(X['pickup_longitude'] > -70) | (X['dropoff_longitude'] > -70) \n",
    "                      | (X['pickup_longitude'] < -76) | (X['dropoff_longitude'] < -76)].index.tolist(), inplace=True)\n",
    "    \n",
    "    X.dropna(subset=['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'], axis=0, inplace=True)\n",
    "    \n",
    "    \n",
    "    X['cityblock_dist'] = X.apply(lambda x: sp.spatial.distance.cityblock((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)), axis=1)\n",
    "    X['dist'] = X.apply(lambda x: distance.distance((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)).km, axis=1)\n",
    "    X['Pickup_area'] = X.apply(lambda x: loc_mapping(x.pickup_latitude, x.pickup_longitude), axis=1)\n",
    "    X['Dropoff_area'] = X.apply(lambda x: loc_mapping(x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "    X['weekday'] = X['pickup_datetime'].dt.dayofweek\n",
    "    X['hour'] = X['pickup_datetime'].dt.hour\n",
    "    X['year'] = X['pickup_datetime'].dt.year\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #X['cityblock_dist'] = sp.spatial.distance.cityblock(X.puloc, X.doloc)\n",
    "    \n",
    "    print(X)\n",
    "\n",
    "    #baseline\n",
    "    sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "    cols_with_missing = [col for col in X.columns\n",
    "                     if X[col].isnull().any()]\n",
    "    \n",
    "    print('Missing value columns:', cols_with_missing)\n",
    "    \n",
    "    y=X.fare_amount\n",
    "    X.drop(['fare_amount'], axis=1,inplace=True)\n",
    "    X.drop(['pickup_datetime'], axis=1,inplace=True)    \n",
    "\n",
    "\n",
    "    \n",
    "    # Preprocessing for numerical data\n",
    "    numerical_transformer = SimpleImputer(strategy='median')\n",
    "    \n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    numerical_cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'dist', 'weekday', 'hour', 'year']\n",
    "    categorical_cols = ['Pickup_area', 'Dropoff_area']\n",
    "    \n",
    "\n",
    "    #Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "     ])\n",
    "    \n",
    "    \n",
    "    # Keep selected columns only\n",
    "    my_cols = categorical_cols + numerical_cols\n",
    "    X_red = X[my_cols].copy()\n",
    "    X_test = X_test_full[my_cols].copy()\n",
    "    \n",
    "    \n",
    "    model = XGBRegressor(n_estimators=200, learning_rate=0.1, n_jobs=4, objective=\"reg:squarederror\")\n",
    "    \n",
    "    #model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1,\n",
    "    #         max_depth=4, random_state=0)\n",
    "    \n",
    "    #with n_estimators = 100, max_depth=6, Accuracy 0.821, on test_set= 0.804\n",
    "    #model = RandomForestClassifier(n_estimators=100, max_depth=6, n_jobs=-1, random_state=0)\n",
    "    \n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)])\n",
    "    \n",
    "    # Preprocessing of training data, fit model \n",
    "    my_pipeline.fit(X_red, y)\n",
    "    \n",
    "    scores = cross_val_score(my_pipeline, X_red, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_squared_error')\n",
    "    print('Neg MSE:', scores)\n",
    "    print(\"NEG MSE mean:\", scores.mean())\n",
    "    print('Standard deviation:', scores.std())\n",
    "\n",
    "    test_pred = my_pipeline.predict(X_test)\n",
    "\n",
    "    answer = pd.DataFrame(data=X_test_full_unmod.key, columns=['key'])\n",
    "    answer['fare_amount'] = test_pred\n",
    "\n",
    "    answer.to_csv('answerv5', index=False)\n",
    "    return\n",
    "taxi_fare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude\n",
      "0          -73.9885          40.7584           -73.9838           40.7301\n",
      "1          -73.9918          40.7262           -73.9877           40.7392\n",
      "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude\n",
      "0          -73.9885          40.7584           -73.9838           40.7301\n",
      "1          -73.9918          40.7262           -73.9877           40.7392\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 4 columns):\n",
      "pickup_longitude     2 non-null float64\n",
      "pickup_latitude      2 non-null float64\n",
      "dropoff_longitude    2 non-null float64\n",
      "dropoff_latitude     2 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 192.0 bytes\n",
      "None\n",
      "3.167657039062772 km\n",
      "0.03300000000000125\n",
      "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
      "0          -73.9885          40.7584           -73.9838           40.7301   \n",
      "1          -73.9918          40.7262           -73.9877           40.7392   \n",
      "\n",
      "       dist  cityblock_dist Pickup_area Dropoff_area  \n",
      "0  3.167657          0.0330   Manhattan    Manhattan  \n",
      "1  1.484598          0.0171   Manhattan    Manhattan  \n"
     ]
    }
   ],
   "source": [
    "Xa = pd.DataFrame(np.array([[-73.9885, 40.7584, -73.9838, 40.7301], [-73.9918, 40.7262, -73.9877, 40.7392]]),\n",
    "                     columns = ['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'])\n",
    "print(Xa)\n",
    "\n",
    "#Xa['puloc'] = pd.Series(zip(Xa.pickup_latitude, Xa.pickup_longitude))\n",
    "#Xa['doloc'] = pd.Series(zip(Xa.dropoff_latitude, Xa.dropoff_longitude))\n",
    "\n",
    "print(Xa)\n",
    "print(Xa.info())\n",
    "\n",
    "Xadist = distance.distance((40.7584, -73.9885), (40.7301, -73.9838))\n",
    "print(Xadist)\n",
    "\n",
    "cityblock_dist = sp.spatial.distance.cityblock((40.7584, -73.9885), (40.7301, -73.9838))\n",
    "print(cityblock_dist)\n",
    "\n",
    "\n",
    "    #X['cityblock_dist'] = sp.spatial.distance.cityblock(X.puloc, X.doloc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Xa['dist'] = Xa.apply(lambda x: distance.distance((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)).km, axis=1)\n",
    "Xa['cityblock_dist'] = Xa.apply(lambda x: sp.spatial.distance.cityblock((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)), axis=1)\n",
    "\n",
    "\n",
    "Xa['Pickup_area'] = Xa.apply(lambda x: loc_mapping(x.pickup_latitude, x.pickup_longitude), axis=1)\n",
    "Xa['Dropoff_area'] = Xa.apply(lambda x: loc_mapping(x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(Xa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
