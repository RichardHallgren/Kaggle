{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from geopy import distance\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_data_light():\n",
    "    #function to read in a light dataframe consisting of only parts of the total data\n",
    "    col_datatypes = {'fare_amount': 'float32',\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8'}\n",
    "    \n",
    "    cols = list(col_datatypes.keys())\n",
    "    \n",
    "    #enter 1/n parts of the data to load, lower n increase amount of data\n",
    "    n = 1000\n",
    "    X_light = pd.read_csv('train.csv', dtype=col_datatypes, header=0, usecols=cols,\n",
    "                         skiprows= lambda i : i % n != 0)\n",
    "    X_light['pickup_datetime'] = X_light['pickup_datetime'].str.slice(0, 16)\n",
    "    X_light['pickup_datetime'] = pd.to_datetime(X_light['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "    \n",
    "    print(X_light.info())\n",
    "    \n",
    "    \n",
    "    return X_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_data_testset():\n",
    "    col_datatypes = {\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8',\n",
    "                'key' : 'str'}\n",
    "    cols = list(col_datatypes.keys())\n",
    "    \n",
    "    X_test = pd.read_csv('test.csv', dtype=col_datatypes, header=0, usecols=cols)\n",
    "    \n",
    "\n",
    "    \n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_data_full():\n",
    "    #function to read the complete dataset\n",
    "    col_datatypes = {'fare_amount': 'float32',\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8'}\n",
    "    \n",
    "    cols = list(col_datatypes.keys())\n",
    "    \n",
    "    X_full = pd.read_csv('train.csv', dtype=col_datatypes, header=0, usecols=cols)\n",
    "    \n",
    "    X_full['pickup_datetime'] = X_full['pickup_datetime'].str.slice(0, 16)\n",
    "    X_full['pickup_datetime'] = pd.to_datetime(X_full['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    #print(len(X_full[X_full['pickup_latitude'] > 45].index.tolist()))\n",
    "\n",
    "    \n",
    "    return X_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nyc_mapping():\n",
    "    #function to create polygons(areas) of locations within New York which has specific additional fees, such as airports\n",
    "    #lat / lon vertices of Manhattan_polygon\n",
    "    v0 = [40.697509, -74.011890]\n",
    "    v1 = [40.701999, -74.023220]\n",
    "    v2 = [40.756686, -74.013898]\n",
    "    v3 = [40.828630, -73.962295]\n",
    "    v4 = [40.881317, -73.934646]\n",
    "    v5 = [40.872590, -73.909950]\n",
    "    v6 = [40.835231, -73.933841]\n",
    "    v7 = [40.809128, -73.933438]\n",
    "    v8 = [40.800289, -73.927667]\n",
    "    v9 = [40.774376, -73.939880]\n",
    "    v10 = [40.738207, -73.967730]\n",
    "    v11 = [40.708912, -73.974576]\n",
    "    v12 = [40.704944, -73.998735]\n",
    "    \n",
    "    vx = [v1,v2,v3,v4,v5,v6,v7,v8,v9,v10,v11,v12]\n",
    "    Manhattan_polygon = Polygon(vx)\n",
    "\n",
    "    #lat / lon vertices of JFK Airport\n",
    "    \n",
    "    jf1 = [40.622718, -73.770487]\n",
    "    jf2 = [40.648282, -73.829434]\n",
    "    jf3 = [40.666631, -73.833526]\n",
    "    jf4 = [40.669141, -73.801063]\n",
    "    jf5 = [40.668668, -73.781136]\n",
    "    jf6 = [40.640110, -73.736205]\n",
    "    \n",
    "    jfx = [jf1, jf2, jf3, jf4, jf5, jf6]\n",
    "    \n",
    "    JFK_polygon = Polygon(jfx)\n",
    "    \n",
    "    #lat / lon vertices of Newark airport\n",
    "    \n",
    "    n1 = [40.663831, -74.179334]\n",
    "    n2 = [40.680684, -74.195557]\n",
    "    n3 = [40.691124, -74.198349]\n",
    "    n4 = [40.712151, -74.181308]\n",
    "    n5 = [40.709275, -74.148121]\n",
    "    n6 = [40.687747, -74.159393]\n",
    "    \n",
    "    nx = [n1, n2, n3, n4, n5, n6]\n",
    "    \n",
    "    Newark_polygon = Polygon(nx)\n",
    "    \n",
    "\n",
    "    #testy = Point(40.831296, -73.923056) #test of location in Bronx\n",
    "    #testjfk = Point(40.646945, -73.789158) #test of location at JFK\n",
    "    \n",
    "    #print(Manhattan_polygon.contains(testy))\n",
    "    #print(JFK_polygon.contains(testjfk))\n",
    "    locations = [Manhattan_polygon, JFK_polygon, Newark_polygon]\n",
    "\n",
    "\n",
    "    \n",
    "    return locations    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_mapping(lat, lon):\n",
    "    #function to return the location of a specific coordinate\n",
    "    Manhattan_polygon = nyc_mapping()[0]\n",
    "    JFK = nyc_mapping()[1]\n",
    "    Newark = nyc_mapping()[2]\n",
    "\n",
    "\n",
    "    location = 'unknown'\n",
    "    \n",
    "    if Manhattan_polygon.contains(Point(lat, lon)):\n",
    "        location = 'Manhattan'\n",
    "        \n",
    "    if location == 'unknown' and JFK.contains(Point(lat, lon)):\n",
    "        location = 'JFK'\n",
    "    \n",
    "    if location == 'unknown' and Newark.contains(Point(lat, lon)):\n",
    "        location = 'Newark'\n",
    "    \n",
    "    return location\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55423 entries, 0 to 55422\n",
      "Data columns (total 7 columns):\n",
      "fare_amount          55423 non-null float32\n",
      "pickup_datetime      55423 non-null datetime64[ns, UTC]\n",
      "pickup_longitude     55423 non-null float32\n",
      "pickup_latitude      55423 non-null float32\n",
      "dropoff_longitude    55423 non-null float32\n",
      "dropoff_latitude     55423 non-null float32\n",
      "passenger_count      55423 non-null uint8\n",
      "dtypes: datetime64[ns, UTC](1), float32(5), uint8(1)\n",
      "memory usage: 1.5 MB\n",
      "None\n",
      "       fare_amount           pickup_datetime  pickup_longitude  \\\n",
      "0        10.900000 2012-05-18 18:41:00+00:00          -73.9885   \n",
      "1         7.500000 2015-02-01 02:25:00+00:00          -73.9918   \n",
      "2        56.799999 2012-10-23 07:57:00+00:00          -73.9882   \n",
      "3        14.500000 2010-07-31 22:24:00+00:00          -73.9845   \n",
      "4        13.300000 2011-02-28 18:37:00+00:00          -73.9833   \n",
      "...            ...                       ...               ...   \n",
      "55418    10.500000 2013-02-03 22:29:00+00:00          -73.9849   \n",
      "55419    17.500000 2012-12-22 03:38:00+00:00          -73.9842   \n",
      "55420     8.500000 2013-10-14 08:27:00+00:00          -73.9716   \n",
      "55421    14.900000 2009-08-05 07:43:00+00:00          -74.0000   \n",
      "55422     8.000000 2012-11-13 15:04:00+00:00          -73.9725   \n",
      "\n",
      "       pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
      "0              40.7584           -73.9838           40.7301                1   \n",
      "1              40.7262           -73.9877           40.7392                5   \n",
      "2              40.7401           -73.7824           40.6467                2   \n",
      "3              40.7590           -74.0117           40.7078                2   \n",
      "4              40.7437           -73.9645           40.7108                1   \n",
      "...                ...                ...               ...              ...   \n",
      "55418          40.7298           -74.0018           40.7467                1   \n",
      "55419          40.7491           -73.9118           40.7610                1   \n",
      "55420          40.7552           -73.9784           40.7514                1   \n",
      "55421          40.6786           -74.0072           40.7287                1   \n",
      "55422          40.7654           -73.9630           40.7724                1   \n",
      "\n",
      "       cityblock_dist       dist Pickup_area Dropoff_area  weekday  hour  year  \n",
      "0              0.0330   3.167657   Manhattan    Manhattan        4    18  2012  \n",
      "1              0.0171   1.484598   Manhattan    Manhattan        6     2  2015  \n",
      "2              0.2992  20.252454   Manhattan          JFK        1     7  2012  \n",
      "3              0.0784   6.132409   Manhattan    Manhattan        5    22  2010  \n",
      "4              0.0517   3.983790   Manhattan      unknown        0    18  2011  \n",
      "...               ...        ...         ...          ...      ...   ...   ...  \n",
      "55418          0.0338   2.357931   Manhattan    Manhattan        6    22  2013  \n",
      "55419          0.0843   6.255068   Manhattan      unknown        5     3  2012  \n",
      "55420          0.0106   0.712624   Manhattan    Manhattan        0     8  2013  \n",
      "55421          0.0573   5.596690     unknown    Manhattan        2     7  2009  \n",
      "55422          0.0165   1.116952   Manhattan    Manhattan        1    15  2012  \n",
      "\n",
      "[54228 rows x 14 columns]\n",
      "Missing value columns: []\n",
      "MSE: 15.239699\n"
     ]
    }
   ],
   "source": [
    "def taxi_fare():\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from xgboost import XGBRegressor\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    import scipy as sp\n",
    "    from pandarallel import pandarallel\n",
    "\n",
    "    #using pandarallel to run pandas in parallel. decreases computing time\n",
    "    pandarallel.initialize()\n",
    "\n",
    "\n",
    "    X_test_full = taxi_data_testset()\n",
    "    \n",
    "    X_test_full_unmod = X_test_full.copy()\n",
    "    \n",
    "    X_test_full['pickup_datetime'] = X_test_full['pickup_datetime'].str.slice(0, 16)\n",
    "    X_test_full['pickup_datetime'] = pd.to_datetime(X_test_full['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "    X_test_full['dist'] = X_test_full.parallel_apply(lambda x: distance.distance((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)).km, axis=1)\n",
    "    X_test_full['Pickup_area'] = X_test_full.parallel_apply(lambda x: loc_mapping(x.pickup_latitude, x.pickup_longitude), axis=1)\n",
    "    X_test_full['Dropoff_area'] = X_test_full.parallel_apply(lambda x: loc_mapping(x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "    X_test_full['weekday'] = X_test_full['pickup_datetime'].dt.dayofweek\n",
    "    X_test_full['hour'] = X_test_full['pickup_datetime'].dt.hour\n",
    "    X_test_full['year'] = X_test_full['pickup_datetime'].dt.year\n",
    "    X_test_full.drop(['pickup_datetime'], axis=1,inplace=True)\n",
    "    X_test_full.drop(['key'], axis=1,inplace=True)    \n",
    "\n",
    "\n",
    "\n",
    "    #choose which dataframe to load\n",
    "    #X = taxi_data_full() \n",
    "    X = taxi_data_light()\n",
    "    cols = ['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "\n",
    "    for col in cols:\n",
    "        X[col] = X[col].astype(float).round(4)\n",
    "        \n",
    "    #drop rows with deviating values and NaN\n",
    "    X.drop(X[(X['pickup_latitude'] > 45) | (X['dropoff_latitude'] > 45) \n",
    "                      | (X['pickup_latitude'] < 35) | (X['dropoff_latitude'] < 35)].index.tolist(), inplace=True)\n",
    "    \n",
    "    X.drop(X[(X['pickup_longitude'] > -70) | (X['dropoff_longitude'] > -70) \n",
    "                      | (X['pickup_longitude'] < -76) | (X['dropoff_longitude'] < -76)].index.tolist(), inplace=True)\n",
    "    \n",
    "    X.dropna(subset=['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'], axis=0, inplace=True)\n",
    "    \n",
    "    \n",
    "    X['cityblock_dist'] = X.parallel_apply(lambda x: sp.spatial.distance.cityblock((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)), axis=1)\n",
    "    X['dist'] = X.parallel_apply(lambda x: distance.distance((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)).km, axis=1)\n",
    "    X['Pickup_area'] = X.parallel_apply(lambda x: loc_mapping(x.pickup_latitude, x.pickup_longitude), axis=1)\n",
    "    X['Dropoff_area'] = X.parallel_apply(lambda x: loc_mapping(x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "    X['weekday'] = X['pickup_datetime'].dt.dayofweek\n",
    "    X['hour'] = X['pickup_datetime'].dt.hour\n",
    "    X['year'] = X['pickup_datetime'].dt.year\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #X['cityblock_dist'] = sp.spatial.distance.cityblock(X.puloc, X.doloc)\n",
    "    \n",
    "    print(X)\n",
    "\n",
    "    #baseline\n",
    "    #sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "    cols_with_missing = [col for col in X.columns\n",
    "                     if X[col].isnull().any()]\n",
    "    \n",
    "    print('Missing value columns:', cols_with_missing)\n",
    "    \n",
    "    y=X.fare_amount\n",
    "    X.drop(['fare_amount'], axis=1,inplace=True)\n",
    "    X.drop(['pickup_datetime'], axis=1,inplace=True)    \n",
    "\n",
    "\n",
    "    \n",
    "    # Preprocessing for numerical data\n",
    "    numerical_transformer = SimpleImputer(strategy='median')\n",
    "    \n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    numerical_cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'dist', 'weekday', 'hour', 'year']\n",
    "    categorical_cols = ['Pickup_area', 'Dropoff_area']\n",
    "    \n",
    "\n",
    "    #Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "     ])\n",
    "    \n",
    "    \n",
    "    # Keep selected columns only\n",
    "    my_cols = categorical_cols + numerical_cols\n",
    "    X_red = X[my_cols].copy()\n",
    "    X_test_kaggle = X_test_full[my_cols].copy()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_red, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    eval_set = [(X_test, y_test)]\n",
    "    \n",
    "    model = XGBRegressor(n_estimators=200, learning_rate=0.1, n_jobs=4, objective=\"reg:squarederror\", eval_metric = 'rmse', eval_set = eval_set, early_stopping_rounds = 10, predictor = 'cpu_predictor')\n",
    "        \n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)])\n",
    "    \n",
    "    # Preprocessing of training data, fit model \n",
    "    my_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = my_pipeline.predict(X_test)\n",
    "    print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    #scores = cross_val_score(my_pipeline, X_red, y,\n",
    "    #                          cv=5,\n",
    "    #                          scoring='neg_mean_squared_error', n_jobs=4)\n",
    "    #print('Neg MSE:', scores)\n",
    "    #print(\"NEG MSE mean:\", scores.mean())\n",
    "    #print('Standard deviation:', scores.std())\n",
    "\n",
    "    test_pred = my_pipeline.predict(X_test_kaggle)\n",
    "\n",
    "    answer = pd.DataFrame(data=X_test_full_unmod.key, columns=['key'])\n",
    "    answer['fare_amount'] = test_pred\n",
    "\n",
    "    answer.to_csv('answern3_new', index=False)\n",
    "    return\n",
    "taxi_fare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa = pd.DataFrame(np.array([[-73.9885, 40.7584, -73.9838, 40.7301], [-73.9918, 40.7262, -73.9877, 40.7392]]),\n",
    "                     columns = ['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'])\n",
    "print(Xa)\n",
    "\n",
    "#Xa['puloc'] = pd.Series(zip(Xa.pickup_latitude, Xa.pickup_longitude))\n",
    "#Xa['doloc'] = pd.Series(zip(Xa.dropoff_latitude, Xa.dropoff_longitude))\n",
    "\n",
    "print(Xa)\n",
    "print(Xa.info())\n",
    "\n",
    "Xadist = distance.distance((40.7584, -73.9885), (40.7301, -73.9838))\n",
    "print(Xadist)\n",
    "\n",
    "cityblock_dist = sp.spatial.distance.cityblock((40.7584, -73.9885), (40.7301, -73.9838))\n",
    "print(cityblock_dist)\n",
    "\n",
    "\n",
    "    #X['cityblock_dist'] = sp.spatial.distance.cityblock(X.puloc, X.doloc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Xa['dist'] = Xa.apply(lambda x: distance.distance((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)).km, axis=1)\n",
    "Xa['cityblock_dist'] = Xa.apply(lambda x: sp.spatial.distance.cityblock((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)), axis=1)\n",
    "\n",
    "\n",
    "Xa['Pickup_area'] = Xa.apply(lambda x: loc_mapping(x.pickup_latitude, x.pickup_longitude), axis=1)\n",
    "Xa['Dropoff_area'] = Xa.apply(lambda x: loc_mapping(x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(Xa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
