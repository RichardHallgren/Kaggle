{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from geopy import distance\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_data_light():\n",
    "    col_datatypes = {'fare_amount': 'float32',\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8'}\n",
    "    \n",
    "    cols = list(col_datatypes.keys())\n",
    "    \n",
    "    n = 3\n",
    "    X_light = pd.read_csv('train.csv', dtype=col_datatypes, header=0, usecols=cols,\n",
    "                         skiprows= lambda i : i % n != 0)\n",
    "    X_light['pickup_datetime'] = X_light['pickup_datetime'].str.slice(0, 16)\n",
    "    X_light['pickup_datetime'] = pd.to_datetime(X_light['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "    \n",
    "    print(X_light.info())\n",
    "    \n",
    "    \n",
    "    return X_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_data_testset():\n",
    "    col_datatypes = {\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8',\n",
    "                'key' : 'str'}\n",
    "    cols = list(col_datatypes.keys())\n",
    "    \n",
    "    X_test = pd.read_csv('test.csv', dtype=col_datatypes, header=0, usecols=cols)\n",
    "    \n",
    "\n",
    "    \n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_data_full():\n",
    "    col_datatypes = {'fare_amount': 'float32',\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8'}\n",
    "    \n",
    "    cols = list(col_datatypes.keys())\n",
    "    \n",
    "    X_full = pd.read_csv('train.csv', dtype=col_datatypes, header=0, usecols=cols)\n",
    "    \n",
    "    X_full['pickup_datetime'] = X_full['pickup_datetime'].str.slice(0, 16)\n",
    "    X_full['pickup_datetime'] = pd.to_datetime(X_full['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    #print(len(X_full[X_full['pickup_latitude'] > 45].index.tolist()))\n",
    "\n",
    "    \n",
    "    return X_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nyc_mapping():\n",
    "    #lat / lon vertices of Manhattan_polygon\n",
    "    v0 = [40.697509, -74.011890]\n",
    "    v1 = [40.701999, -74.023220]\n",
    "    v2 = [40.756686, -74.013898]\n",
    "    v3 = [40.828630, -73.962295]\n",
    "    v4 = [40.881317, -73.934646]\n",
    "    v5 = [40.872590, -73.909950]\n",
    "    v6 = [40.835231, -73.933841]\n",
    "    v7 = [40.809128, -73.933438]\n",
    "    v8 = [40.800289, -73.927667]\n",
    "    v9 = [40.774376, -73.939880]\n",
    "    v10 = [40.738207, -73.967730]\n",
    "    v11 = [40.708912, -73.974576]\n",
    "    v12 = [40.704944, -73.998735]\n",
    "    \n",
    "    vx = [v1,v2,v3,v4,v5,v6,v7,v8,v9,v10,v11,v12]\n",
    "    Manhattan_polygon = Polygon(vx)\n",
    "\n",
    "    #lat / lon vertices of JFK Airport\n",
    "    \n",
    "    jf1 = [40.622718, -73.770487]\n",
    "    jf2 = [40.648282, -73.829434]\n",
    "    jf3 = [40.666631, -73.833526]\n",
    "    jf4 = [40.669141, -73.801063]\n",
    "    jf5 = [40.668668, -73.781136]\n",
    "    jf6 = [40.640110, -73.736205]\n",
    "    \n",
    "    jfx = [jf1, jf2, jf3, jf4, jf5, jf6]\n",
    "    \n",
    "    JFK_polygon = Polygon(jfx)\n",
    "    \n",
    "    #lat / lon vertices of Newark airport\n",
    "    \n",
    "    n1 = [40.663831, -74.179334]\n",
    "    n2 = [40.680684, -74.195557]\n",
    "    n3 = [40.691124, -74.198349]\n",
    "    n4 = [40.712151, -74.181308]\n",
    "    n5 = [40.709275, -74.148121]\n",
    "    n6 = [40.687747, -74.159393]\n",
    "    \n",
    "    nx = [n1, n2, n3, n4, n5, n6]\n",
    "    \n",
    "    Newark_polygon = Polygon(nx)\n",
    "    \n",
    "\n",
    "    #testy = Point(40.831296, -73.923056) #test of location in Bronx\n",
    "    #testjfk = Point(40.646945, -73.789158) #test of location at JFK\n",
    "    \n",
    "    #print(Manhattan_polygon.contains(testy))\n",
    "    #print(JFK_polygon.contains(testjfk))\n",
    "    locations = [Manhattan_polygon, JFK_polygon, Newark_polygon]\n",
    "\n",
    "\n",
    "    \n",
    "    return locations    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_mapping(lat, lon):\n",
    "    Manhattan_polygon = nyc_mapping()[0]\n",
    "    JFK = nyc_mapping()[1]\n",
    "    Newark = nyc_mapping()[2]\n",
    "\n",
    "\n",
    "    location = 'unknown'\n",
    "    \n",
    "    if Manhattan_polygon.contains(Point(lat, lon)):\n",
    "        location = 'Manhattan'\n",
    "        \n",
    "    if location == 'unknown' and JFK.contains(Point(lat, lon)):\n",
    "        location = 'JFK'\n",
    "    \n",
    "    if location == 'unknown' and Newark.contains(Point(lat, lon)):\n",
    "        location = 'Newark'\n",
    "    \n",
    "    return location\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18474618 entries, 0 to 18474617\n",
      "Data columns (total 7 columns):\n",
      "fare_amount          float32\n",
      "pickup_datetime      datetime64[ns, UTC]\n",
      "pickup_longitude     float32\n",
      "pickup_latitude      float32\n",
      "dropoff_longitude    float32\n",
      "dropoff_latitude     float32\n",
      "passenger_count      uint8\n",
      "dtypes: datetime64[ns, UTC](1), float32(5), uint8(1)\n",
      "memory usage: 510.9 MB\n",
      "None\n",
      "          fare_amount           pickup_datetime  pickup_longitude  \\\n",
      "0                 5.7 2011-08-18 00:35:00+00:00          -73.9827   \n",
      "1                12.1 2011-01-06 09:50:00+00:00          -74.0010   \n",
      "2                 9.0 2012-12-03 13:10:00+00:00          -74.0065   \n",
      "4                 7.7 2011-04-05 17:11:00+00:00          -74.0018   \n",
      "5                 5.3 2009-07-22 16:08:00+00:00          -73.9811   \n",
      "...               ...                       ...               ...   \n",
      "18474613          6.5 2014-05-02 07:36:00+00:00          -73.9898   \n",
      "18474614         18.0 2015-06-13 20:45:00+00:00          -73.9873   \n",
      "18474615          6.1 2011-09-16 00:46:00+00:00          -73.9909   \n",
      "18474616          4.5 2015-03-22 16:37:00+00:00          -73.9811   \n",
      "18474617         14.1 2011-04-02 22:04:00+00:00          -73.9705   \n",
      "\n",
      "          pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
      "0                 40.7613           -73.9912           40.7506   \n",
      "1                 40.7316           -73.9729           40.7582   \n",
      "2                 40.7267           -73.9931           40.7316   \n",
      "4                 40.7375           -73.9981           40.7228   \n",
      "5                 40.7377           -73.9942           40.7284   \n",
      "...                   ...                ...               ...   \n",
      "18474613          40.7391           -73.9869           40.7517   \n",
      "18474614          40.7553           -74.0152           40.7102   \n",
      "18474615          40.7366           -73.9923           40.7403   \n",
      "18474616          40.7375           -73.9855           40.7293   \n",
      "18474617          40.7523           -73.9605           40.7973   \n",
      "\n",
      "          passenger_count  cityblock_dist      dist Pickup_area Dropoff_area  \\\n",
      "0                       2          0.0192  1.388197   Manhattan    Manhattan   \n",
      "1                       1          0.0547  3.789202   Manhattan    Manhattan   \n",
      "2                       1          0.0183  1.256003   Manhattan    Manhattan   \n",
      "4                       2          0.0184  1.662071   Manhattan    Manhattan   \n",
      "5                       1          0.0224  1.513656   Manhattan    Manhattan   \n",
      "...                   ...             ...       ...         ...          ...   \n",
      "18474613                1          0.0155  1.420493   Manhattan    Manhattan   \n",
      "18474614                2          0.0730  5.535132   Manhattan    Manhattan   \n",
      "18474615                3          0.0051  0.427559   Manhattan    Manhattan   \n",
      "18474616                1          0.0126  0.983534   Manhattan    Manhattan   \n",
      "18474617                1          0.0550  5.068037   Manhattan    Manhattan   \n",
      "\n",
      "          weekday  hour  year  \n",
      "0               3     0  2011  \n",
      "1               3     9  2011  \n",
      "2               0    13  2012  \n",
      "4               1    17  2011  \n",
      "5               2    16  2009  \n",
      "...           ...   ...   ...  \n",
      "18474613        4     7  2014  \n",
      "18474614        5    20  2015  \n",
      "18474615        4     0  2011  \n",
      "18474616        6    16  2015  \n",
      "18474617        5    22  2011  \n",
      "\n",
      "[18090446 rows x 14 columns]\n",
      "Missing value columns: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:27:08] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
     ]
    }
   ],
   "source": [
    "def taxi_fare():\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from xgboost import XGBRegressor\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    import scipy as sp\n",
    "    from pandarallel import pandarallel\n",
    "\n",
    "    pandarallel.initialize()\n",
    "\n",
    "\n",
    "    X_test_full = taxi_data_testset()\n",
    "    \n",
    "    X_test_full_unmod = X_test_full.copy()\n",
    "    \n",
    "    X_test_full['pickup_datetime'] = X_test_full['pickup_datetime'].str.slice(0, 16)\n",
    "    X_test_full['pickup_datetime'] = pd.to_datetime(X_test_full['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "    X_test_full['dist'] = X_test_full.parallel_apply(lambda x: distance.distance((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)).km, axis=1)\n",
    "    X_test_full['Pickup_area'] = X_test_full.parallel_apply(lambda x: loc_mapping(x.pickup_latitude, x.pickup_longitude), axis=1)\n",
    "    X_test_full['Dropoff_area'] = X_test_full.parallel_apply(lambda x: loc_mapping(x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "    X_test_full['weekday'] = X_test_full['pickup_datetime'].dt.dayofweek\n",
    "    X_test_full['hour'] = X_test_full['pickup_datetime'].dt.hour\n",
    "    X_test_full['year'] = X_test_full['pickup_datetime'].dt.year\n",
    "    X_test_full.drop(['pickup_datetime'], axis=1,inplace=True)\n",
    "    X_test_full.drop(['key'], axis=1,inplace=True)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #X = taxi_data_full() \n",
    "    X = taxi_data_light()\n",
    "    cols = ['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "\n",
    "    for col in cols:\n",
    "        X[col] = X[col].astype(float).round(4)\n",
    "        \n",
    "    #drop rows with deviating values and NaN\n",
    "    X.drop(X[(X['pickup_latitude'] > 45) | (X['dropoff_latitude'] > 45) \n",
    "                      | (X['pickup_latitude'] < 35) | (X['dropoff_latitude'] < 35)].index.tolist(), inplace=True)\n",
    "    \n",
    "    X.drop(X[(X['pickup_longitude'] > -70) | (X['dropoff_longitude'] > -70) \n",
    "                      | (X['pickup_longitude'] < -76) | (X['dropoff_longitude'] < -76)].index.tolist(), inplace=True)\n",
    "    \n",
    "    X.dropna(subset=['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'], axis=0, inplace=True)\n",
    "    \n",
    "    \n",
    "    X['cityblock_dist'] = X.parallel_apply(lambda x: sp.spatial.distance.cityblock((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)), axis=1)\n",
    "    X['dist'] = X.parallel_apply(lambda x: distance.distance((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)).km, axis=1)\n",
    "    X['Pickup_area'] = X.parallel_apply(lambda x: loc_mapping(x.pickup_latitude, x.pickup_longitude), axis=1)\n",
    "    X['Dropoff_area'] = X.parallel_apply(lambda x: loc_mapping(x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "    X['weekday'] = X['pickup_datetime'].dt.dayofweek\n",
    "    X['hour'] = X['pickup_datetime'].dt.hour\n",
    "    X['year'] = X['pickup_datetime'].dt.year\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #X['cityblock_dist'] = sp.spatial.distance.cityblock(X.puloc, X.doloc)\n",
    "    \n",
    "    print(X)\n",
    "\n",
    "    #baseline\n",
    "    #sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "    cols_with_missing = [col for col in X.columns\n",
    "                     if X[col].isnull().any()]\n",
    "    \n",
    "    print('Missing value columns:', cols_with_missing)\n",
    "    \n",
    "    y=X.fare_amount\n",
    "    X.drop(['fare_amount'], axis=1,inplace=True)\n",
    "    X.drop(['pickup_datetime'], axis=1,inplace=True)    \n",
    "\n",
    "\n",
    "    \n",
    "    # Preprocessing for numerical data\n",
    "    numerical_transformer = SimpleImputer(strategy='median')\n",
    "    \n",
    "    # Preprocessing for categorical data\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    numerical_cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'dist', 'weekday', 'hour', 'year']\n",
    "    categorical_cols = ['Pickup_area', 'Dropoff_area']\n",
    "    \n",
    "\n",
    "    #Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "     ])\n",
    "    \n",
    "    \n",
    "    # Keep selected columns only\n",
    "    my_cols = categorical_cols + numerical_cols\n",
    "    X_red = X[my_cols].copy()\n",
    "    X_test_kaggle = X_test_full[my_cols].copy()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_red, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    eval_set = [(X_test, y_test)]\n",
    "    \n",
    "    model = XGBRegressor(n_estimators=200, learning_rate=0.1, n_jobs=4, objective=\"reg:squarederror\", eval_metric = 'rmse', eval_set = eval_set, early_stopping_rounds = 10, predictor = 'cpu_predictor')\n",
    "        \n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)])\n",
    "    \n",
    "    # Preprocessing of training data, fit model \n",
    "    my_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = my_pipeline.predict(X_test)\n",
    "    print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    #scores = cross_val_score(my_pipeline, X_red, y,\n",
    "    #                          cv=5,\n",
    "    #                          scoring='neg_mean_squared_error', n_jobs=4)\n",
    "    #print('Neg MSE:', scores)\n",
    "    #print(\"NEG MSE mean:\", scores.mean())\n",
    "    #print('Standard deviation:', scores.std())\n",
    "\n",
    "    test_pred = my_pipeline.predict(X_test_kaggle)\n",
    "\n",
    "    answer = pd.DataFrame(data=X_test_full_unmod.key, columns=['key'])\n",
    "    answer['fare_amount'] = test_pred\n",
    "\n",
    "    answer.to_csv('answern3_new', index=False)\n",
    "    return\n",
    "taxi_fare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa = pd.DataFrame(np.array([[-73.9885, 40.7584, -73.9838, 40.7301], [-73.9918, 40.7262, -73.9877, 40.7392]]),\n",
    "                     columns = ['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'])\n",
    "print(Xa)\n",
    "\n",
    "#Xa['puloc'] = pd.Series(zip(Xa.pickup_latitude, Xa.pickup_longitude))\n",
    "#Xa['doloc'] = pd.Series(zip(Xa.dropoff_latitude, Xa.dropoff_longitude))\n",
    "\n",
    "print(Xa)\n",
    "print(Xa.info())\n",
    "\n",
    "Xadist = distance.distance((40.7584, -73.9885), (40.7301, -73.9838))\n",
    "print(Xadist)\n",
    "\n",
    "cityblock_dist = sp.spatial.distance.cityblock((40.7584, -73.9885), (40.7301, -73.9838))\n",
    "print(cityblock_dist)\n",
    "\n",
    "\n",
    "    #X['cityblock_dist'] = sp.spatial.distance.cityblock(X.puloc, X.doloc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Xa['dist'] = Xa.apply(lambda x: distance.distance((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)).km, axis=1)\n",
    "Xa['cityblock_dist'] = Xa.apply(lambda x: sp.spatial.distance.cityblock((x.pickup_latitude, x.pickup_longitude), (x.dropoff_latitude, x.dropoff_longitude)), axis=1)\n",
    "\n",
    "\n",
    "Xa['Pickup_area'] = Xa.apply(lambda x: loc_mapping(x.pickup_latitude, x.pickup_longitude), axis=1)\n",
    "Xa['Dropoff_area'] = Xa.apply(lambda x: loc_mapping(x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(Xa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
